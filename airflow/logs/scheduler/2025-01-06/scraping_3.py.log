[2025-01-06T20:56:44.020+0000] {processor.py:161} INFO - Started process (PID=4018) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T20:56:44.021+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T20:56:44.024+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:56:44.023+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:56:44.036+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:56:44.212+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:56:44.211+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T20:56:44.232+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:56:44.232+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T20:56:44.258+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.245 seconds
[2025-01-06T20:57:14.563+0000] {processor.py:161} INFO - Started process (PID=4030) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T20:57:14.566+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T20:57:14.569+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:57:14.568+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:57:14.586+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:57:14.777+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:57:14.776+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T20:57:14.794+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:57:14.794+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T20:57:14.824+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.269 seconds
[2025-01-06T20:57:45.067+0000] {processor.py:161} INFO - Started process (PID=4042) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T20:57:45.070+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T20:57:45.073+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:57:45.073+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:57:45.093+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:57:45.273+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:57:45.272+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T20:57:45.290+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:57:45.290+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T20:57:45.318+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.259 seconds
[2025-01-06T20:58:16.267+0000] {processor.py:161} INFO - Started process (PID=4054) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T20:58:16.269+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T20:58:16.273+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:58:16.272+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:58:16.289+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:58:16.460+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:58:16.459+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T20:58:16.480+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:58:16.480+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T20:58:16.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.249 seconds
[2025-01-06T20:58:46.974+0000] {processor.py:161} INFO - Started process (PID=4066) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T20:58:46.976+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T20:58:46.978+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:58:46.978+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:58:46.992+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:58:47.164+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:58:47.163+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T20:58:47.181+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:58:47.181+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T20:58:47.217+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.249 seconds
[2025-01-06T20:59:17.741+0000] {processor.py:161} INFO - Started process (PID=4077) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T20:59:17.743+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T20:59:17.746+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:59:17.745+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:59:17.759+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:59:17.936+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:59:17.935+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T20:59:17.954+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:59:17.954+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T20:59:17.983+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.250 seconds
[2025-01-06T20:59:48.247+0000] {processor.py:161} INFO - Started process (PID=4082) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T20:59:48.249+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T20:59:48.252+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:59:48.251+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:59:48.264+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T20:59:48.427+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:59:48.426+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T20:59:48.447+0000] {logging_mixin.py:188} INFO - [2025-01-06T20:59:48.446+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T20:59:48.475+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.234 seconds
[2025-01-06T21:00:18.775+0000] {processor.py:161} INFO - Started process (PID=4094) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:00:18.777+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:00:18.781+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:00:18.780+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:00:18.798+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:00:19.028+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:00:19.027+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:00:19.053+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:00:19.052+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:00:19.096+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.329 seconds
[2025-01-06T21:00:50.078+0000] {processor.py:161} INFO - Started process (PID=4106) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:00:50.080+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:00:50.082+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:00:50.082+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:00:50.096+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:00:50.285+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:00:50.285+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:00:50.303+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:00:50.302+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:00:50.348+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.278 seconds
[2025-01-06T21:01:20.912+0000] {processor.py:161} INFO - Started process (PID=4118) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:01:20.914+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:01:20.917+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:01:20.917+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:01:20.932+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:01:21.179+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:01:21.179+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:01:21.205+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:01:21.204+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:01:21.235+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.331 seconds
[2025-01-06T21:01:51.748+0000] {processor.py:161} INFO - Started process (PID=4130) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:01:51.750+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:01:51.753+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:01:51.752+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:01:51.771+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:01:51.983+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:01:51.983+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:01:52.005+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:01:52.005+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:01:52.051+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.309 seconds
[2025-01-06T21:02:22.362+0000] {processor.py:161} INFO - Started process (PID=4143) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:02:22.364+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:02:22.366+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:02:22.366+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:02:22.380+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:02:22.553+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:02:22.552+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:02:22.569+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:02:22.569+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:02:22.596+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.242 seconds
[2025-01-06T21:02:53.392+0000] {processor.py:161} INFO - Started process (PID=4157) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:02:53.394+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:02:53.398+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:02:53.398+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:02:53.415+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:02:53.616+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:02:53.616+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:02:53.637+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:02:53.636+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:02:53.673+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.286 seconds
[2025-01-06T21:03:24.456+0000] {processor.py:161} INFO - Started process (PID=4170) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:03:24.458+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:03:24.460+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:03:24.459+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:03:24.477+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:03:24.649+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:03:24.649+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:03:24.670+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:03:24.670+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:03:24.703+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.253 seconds
[2025-01-06T21:03:55.281+0000] {processor.py:161} INFO - Started process (PID=4182) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:03:55.283+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:03:55.284+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:03:55.284+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:03:55.300+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:03:55.468+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:03:55.467+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:03:55.484+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:03:55.484+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:03:55.509+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.233 seconds
[2025-01-06T21:04:26.054+0000] {processor.py:161} INFO - Started process (PID=4193) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:04:26.056+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:04:26.057+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:04:26.057+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:04:26.071+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:04:26.233+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:04:26.233+0000] {dag.py:3036} INFO - Sync 1 DAGs
[2025-01-06T21:04:26.256+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:04:26.255+0000] {dag.py:3823} INFO - Setting next_dagrun for process_csv_workflow to None, run_after=None
[2025-01-06T21:04:26.289+0000] {processor.py:183} INFO - Processing /opt/airflow/dags/scraping_3.py took 0.241 seconds
[2025-01-06T21:04:56.546+0000] {processor.py:161} INFO - Started process (PID=4198) to work on /opt/airflow/dags/scraping_3.py
[2025-01-06T21:04:56.548+0000] {processor.py:830} INFO - Processing file /opt/airflow/dags/scraping_3.py for tasks to queue
[2025-01-06T21:04:56.550+0000] {logging_mixin.py:188} INFO - [2025-01-06T21:04:56.549+0000] {dagbag.py:538} INFO - Filling up the DagBag from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:04:56.568+0000] {processor.py:840} INFO - DAG(s) 'process_csv_workflow' retrieved from /opt/airflow/dags/scraping_3.py
[2025-01-06T21:04:57.512+0000] {processor.py:186} ERROR - Got an exception! Propagating...
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
psycopg2.OperationalError: connection to server at "postgres" (192.168.48.3), port 5432 failed: FATAL:  could not open file "global/pg_filenode.map": No such file or directory


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 182, in _run_file_processor
    _handle_dag_file_processing()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 163, in _handle_dag_file_processing
    result: tuple[int, int] = dag_file_processor.process_file(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 859, in process_file
    serialize_errors = DagFileProcessor.save_dag_to_db(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/api_internal/internal_api_call.py", line 114, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 79, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/dag_processing/processor.py", line 895, in save_dag_to_db
    import_errors = DagBag._sync_to_db(dags=dags, processor_subdir=dag_directory, session=session)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 657, in _sync_to_db
    for attempt in run_with_db_retries(logger=log):
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 347, in __iter__
    do = self.iter(retry_state=retry_state)
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 325, in iter
    raise retry_exc.reraise()
  File "/home/airflow/.local/lib/python3.8/site-packages/tenacity/__init__.py", line 158, in reraise
    raise self.last_attempt.result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 437, in result
    return self.__get_result()
  File "/usr/local/lib/python3.8/concurrent/futures/_base.py", line 389, in __get_result
    raise self._exception
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 670, in _sync_to_db
    _serialize_dag_capturing_errors(dag, session, processor_subdir)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 635, in _serialize_dag_capturing_errors
    dag_was_updated = SerializedDagModel.write_dag(
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 76, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/serialized_dag.py", line 157, in write_dag
    if session.scalar(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1747, in scalar
    return self.execute(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/future/engine.py", line 412, in connect
    return super(Engine, self).connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 146, in _do_get
    self._dec_overflow()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/impl.py", line 143, in _do_get
    return self._create_connection()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 691, in __connect
    pool.logger.debug("Error on connect(): %s", e)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
  File "/home/airflow/.local/lib/python3.8/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) connection to server at "postgres" (192.168.48.3), port 5432 failed: FATAL:  could not open file "global/pg_filenode.map": No such file or directory

(Background on this error at: https://sqlalche.me/e/14/e3q8)
